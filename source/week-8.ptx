<?xml version='1.0' encoding="utf-8"?>
<!--
% !TEX TS-program = PreTeXt-HTML
-->
<section xml:id="week-8" xmlns:xi="http://www.w3.org/2001/XInclude">
			<title>Week 8</title>
			<subsection>
	<title>Self-test questions for lecture 15</title>
			<exercise>
				<title>Local min/max</title>
				<task>
					<statement>
					Define a local max/min.
					</statement>
					<solution>
					<definition xml:id="def-local-max-min">
<title>Local max/min</title>
 Let <m>D \subset \R</m> and <m>f : D \to \R</m>.
 We say that <m>x_0 \in D</m> is a <em>local maximum</em> for <m>f</m> if there exists <m>\delta \gt 0</m> such that 
<me>
(\forall x \in D\cap [x_0-\delta, x_0+\delta]) [f(x) \leq f(x_0)].
</me>
 We say that <m>x_0 \in (a,b)</m> is a <em>local minimum</em> for <m>f</m> if there exists <m>\delta \gt 0</m> such that 
<me>
(\forall x \in D\cap [x_0-\delta, x_0+\delta]) [f(x) \geq f(x_0)].
</me>
</definition>
					</solution>
				</task>
				<task>
					<statement>
					State and prove how a derivative must be zero at a local max/min.
					</statement>
					<solution>
					<proposition xml:id="lem-zero-deriv">
					<title>The derivative is zero at a local max/min</title>
					<statement>
 Suppose that <m>f : (a,b) \to \R</m> is differentiable at <m>x_0 \in (a,b)</m>.
 Suppose that <m>x_0</m> is a local maximum or local minimum for <m>f</m>.
 Then <m>f'(x_0) = 0</m>.
</statement>
<proof>
 Let us suppose that <m>x_0</m> is a local maximum for <m>f</m>; the argument for the local minimum is similar.
 By definition of a local maximum (see <xref ref="def-local-max-min"/>) there exists <m>\delta \gt 0</m> such that for all <m>x \in (a,b)\cap [x_0-\delta, x_0+\delta]</m> we have <m>f(x_0) \geq f(x)</m>. Decreasing <m>\delta \gt 0</m> if necessary<fn>For instance, take replace <m>\delta</m> with <m>\min\set{\delta, (x_0 - a)/2, (b-x_0)/2}</m>.</fn>, we may assume that 
 <me>
 [x_0-\delta, x_0+\delta] \subset (a,b)
 </me>.
 Hence
 <me>
\frac{f(x)-f(x_0)}{x-x_0}  \begin{cases} \geq 0 \amp \text{ if } x_0-\delta \leq  x \lt  x_0,\\
							\leq 0 \amp \text{ if } x_0 \lt  x \leq  x_0+\delta.\end{cases}
</me>
Setting <m>a_n := x_0-\trecip{n}\delta</m>, the sequential definition of the limit <xref ref="def-fn-lim"/>, the definition of the derivative (<xref ref="def-differentiable"/>) and the inequality rule (<xref ref="prop-ineq-rule"/>) give that
<me>
f'(x_0) = \lim_{n\to \infty}\frac{f(a_n)-f(x_0)}{a_n-x_0} \geq 0.
</me>
 Similarly, setting <m>b_0:= x_0+\trecip{n}\delta</m> gives
<me>
f'(x_0) = \lim_{n\to \infty}\frac{f(b_n)-f(x_0)}{a_n-x_0} \leq 0.
</me>
 Thus <m>f'(x_0) = 0</m>.
</proof>
</proposition>
					</solution>
				</task>
				</exercise>
				<exercise xml:id="ex-rolle">
				<title>Rolle's theorem</title>
					<statement>State and prove Rolle's theorem.</statement>
					<solution>
					<theorem xml:id="lem-rolle">
<title>Rolle's theorem</title>
<statement>
 Let <m>f : [a,b] \to \R</m> be a continuous function which is differentiable on <m>(a,b)</m>, with <m>a \lt  b</m>.
 Suppose that <m>f(a) = f(b)</m>.
 Then there exists <m>x_0 \in (a,b)</m> such that <m>f'(x_0) = 0</m>.
</statement>
<proof>
By the extreme value theorem (<xref ref="thm-extreme"/>), there exists <m>x_1,x_2 \in [a,b]</m> which are minima and maxima (respectively) for <m>f</m> on <m>[a,b]</m>.
 In particular <m>x_1</m> is a local minimum and <m>x_2</m> is a local maximum.
 If <m>x_1 \in (a,b)</m> or <m>x_2 \in (a,b)</m>, then it follows that <m>f'(x_1) = 0</m> or <m>f'(x_2) = 0</m> since local minima/maxima have zero derivative at points of differentiability (<xref ref="lem-zero-deriv"/>).
 We may therefore assume that <m>\set{x_1, x_2} \subset \set{a,b}</m>.
 Hence <m>f(x_1) = f(x_2)</m>.
 For any <m>x \in [a,b]</m>, we have that <m>f(x)</m> is between <m>f(x_1)</m> and <m>f(x_2)</m>.
 Since <m>f(x_1) = f(x_2)</m>, it follows that <m>f</m> is constant on <m>[a,b]</m>.
 It then follows from <xref ref="eg-const-diff"/> that <m>f'(x)= 0</m> at every <m>x \in (a,b)</m>, e.g. for <m>x := \frac{a+b}{2}</m>.
</proof>
</theorem>					</solution>
				</exercise>
				<exercise xml:id="ex-mvt">
				<title>The mean value theorem</title>
					<statement>State and prove the mean value theorem.</statement>
					<solution>
					<theorem xml:id="thm-mvt">
<title>Mean value theorem</title>
<statement>
 Let <m>f : [a,b] \to \R</m> be a continuous function which is differentiable on <m>(a,b)</m>, with <m>a \lt  b</m>.
 Then there exists <m>x_0 \in (a,b)</m> such that 
<men xml:id="eq-mvt">
f(b) - f(a) = f'(x_0)(b-a).
</men>
</statement>
<proof>
 We deduce this result from Rolle's theorem (<xref ref="lem-rolle"/>).
 The idea of the proof is to try and find a continuous function <m>g:[a,b] \to \R</m> which is differentiable on <m>(a,b)</m> with <m>g(a) = g(b)</m> and such that the identity <m>g'(x_0) = 0</m> implies <xref ref="eq-mvt"/>.
 To this end set 
<me>
g(x) :=f(x) - \frac{f(b)-f(a)}{b-a} (x-a), \qquad (x \in [a,b]).
</me>
 This is continuous on <m>[a,b]</m> since constant functions are continuous (<xref ref="eg-const-cts"/>), the identity function is continuous (<xref ref="eg-id-cts"/>) and so is the sum/product of continuous functions (<xref ref="prop-alg-cts"/>).
 The function <m>g</m> is differentiable on <m>(a,b)</m> since constant functions are differentiable (<xref ref="eg-const-diff"/>), the identity function is differentiable (<xref ref="eg-id-diff"/>) and so is the sum/product of differentiable functions (<xref ref="prop-alg-cts"/>).
 We have <m>g(a) = f(a)</m> and <m>g(b)  = f(a)</m>.
 We may therefore apply Rolle's theorem to deduce the existence of <m>x_0 \in (a,b)</m> such that <m>g'(x_0) = 0</m>.
 Employing the sum/product rules for differentiation, we have that
<me>
g'(x_0) = f'(x_0) -\frac{f(b)-f(a)}{b-a}.
</me>
 The result follows on re-arranging the identity
<me>
0 = f'(x_0) -\frac{f(b)-f(a)}{b-a}. 
</me>
</proof>
</theorem>					</solution>
				</exercise>
				<exercise xml:id="ex-mono-diff">
				<title>Monotonicity and the sign of the derivative</title>
					<statement>Prove how a function with non-negative derivative is increasing.</statement>
					<solution>
					<corollary xml:id="cor-mono-diff">
					<statement>
 Let <m>f : [a,b] \to \R</m> be a continuous function which is differentiable on <m>(a,b)</m>, with <m>a \lt  b</m>.
 <ol>
 	<li>
 If <m>(\forall x \in (a,b))[f'(x) \geq 0]</m> then <m>f</m> is increasing.
 	</li>
	<li>
 If <m>(\forall x \in (a,b))[f'(x) \gt 0]</m> then <m>f</m> is strictly increasing.
 </li>
	<li>
 If <m>(\forall x \in (a,b))[f'(x) \leq 0]</m> then <m>f</m> is decreasing.
 </li>
	<li>
 If <m>(\forall x \in (a,b))[f'(x) \lt  0]</m> then <m>f</m> is strictly decreasing.
 </li>
	<li>
 If <m>(\forall x \in (a,b))[f'(x) = 0]</m> then <m>f</m> is constant.
 </li>
</ol>
</statement>
<proof> Let us first suppose that <m>(\forall x \in (a,b))[f'(x) \geq 0]</m>.
 Let <m>x_1, x_2 \in [a,b]</m> with <m>x_1 \lt  x_2</m>.
 Our task is to prove that <m>f(x_1) \leq f(x_2)</m>.
 Applying the mean value theorem to the function <m>f: [x_1, x_2] \to \R</m>, there exists <m>x_0 \in (x_1, x_2)</m> such that
<me>
f(x_2)-f(x_1) = f'(x_0)(x_2-x_1) \geq 0,
</me>
as required.
 Notice that if <m>(\forall x \in (a,b))[f'(x) \gt 0]</m> then  <m>f(x_2) -f(x_1) = f'(x_0)(x_2-x_1) \gt 0</m>, which implies that the function is strictly increasing.
 The conclusions involving decreasing functions follow on applying the increasing results to <m>-f</m>.
 If <m>(\forall x \in (a,b))[f'(x) = 0]</m> then <m>f</m> is both increasing and decreasing, hence for all <m>x \in [a,b]</m> we have <m>f(x) = f(b)</m>. 
 Thus in the latter case <m>f</m> is constant.
</proof>
</corollary>					</solution>
			</exercise>			
			</subsection>
			<subsection>
	<title>Self-test questions for lecture 16</title>
	<!--
	<exercise>
				<title>Taylor's theorem</title>
				<task xml:id="ex-taylor">
					<statement>State Taylor's theorem (the proof is non-examinable).
					</statement>
					<solution>
<theorem xml:id="thm-strong-taylor">
<title>Taylor's theorem</title>
					<statement>
					Let <m>f : (a,b) \to \R</m> be a function which is <m>n</m>-times differentiable and let <m>x_0, x \in (a,b)</m>. Then 
<md>
<mrow>
\Bigl|f(x) - \amp\bigl[f(x_0) + (x-x_0)f'(x_0)  + \dots +  \trecip{(n-1)!} (x-x_0)^{n-1} f^{(n-1)}(x_0)\bigr]\Bigr|
</mrow>
<mrow>
\amp \leq \trecip{n!}|x-x_0|^n\sup\set{|f^{(n)}(t)| : t \text{ is between } x \text{ and } x_0}.
</mrow>
</md>
</statement>
</theorem>
<p>
The following proof of Taylor's theorem is <em>not</em> examinable. 
</p>
<p>
We begin by proving a lemma.
</p>
<lemma xml:id="lem-poly-comp">
<title>Key estimate for Taylor's theorem</title>
<statement>
Let <m>f : (a, b) \to \R</m> be a differentiable function. Let <m>c \in [0, \infty)</m>, <m>n \in \set{0, 1, 2, \dots}</m> and <m>x_0,x \in (a,b)</m> with <m>x_0 \leq x</m>. Suppose that for all <m>t \in [x_0,x]</m> we have
<me>
|f'(t)| \leq c(t-x_0)^n.
</me>
Suppose in addition that <m>f(x_0) = 0</m>. Then for all <m>t\in [x_0,x]</m> we have
<me>
|f(t)| \leq \trecip{n+1} c (t-x_0)^{n+1}
</me>.
</statement>
</lemma>
<proof>
We are assuming that for all <m>t \in [x_0,x]</m> we have
<me>
-c(t-x_0)^n \leq f'(t) \leq  c(t-x_0)^n.
</me>
 Since functions with non-negative derivative are increasing (<xref ref="cor-mono-diff"/>), it follows that the functions
 <me>
 f(t) + \trecip{n+1}c(t-x_0)^{n+1} \qquad \text{and} \qquad  \trecip{n+1}c(t-x_0)^{n+1} -f(t)
 </me> 
 are increasing as <m>t</m> ranges over <m>[x_0,x]</m>. Both of these functions evaluate to zero at <m>t=x_0</m>, hence for all <m>t\in [x_0,x]</m> we have
<me>
 f(t) + \trecip{n+1}c(t-x_0)^{n+1}\geq 0 \geq f(t) - \trecip{n+1}c(t-x_0)^{n+1}.
</me>
 Combining inequalities we deduce that for any <m>t\in [x_0,x]</m> we have
<me>
-\trecip{n+1} c (t-x_0)^{n+1}\leq f(t) \leq \trecip{n+1} c (t-x_0)^{n+1}.
</me> 
 This completes our proof.
</proof>
We are now in a position to prove Taylor's theorem.
<proof>
<title>Proof of Taylor's theorem</title>
<p>
We may assume that <m>x\geq x_0</m>, for if <m>x\leq x_0</m> we obtain the result on applying the following argument to <m>g: (-b, -a) \to \R</m> given by <m>g(x):=f(-x)</m>. 
</p>
<p>
Define the following auxiliary function
<md>
<mrow>
\amp F(x) := f(x)-
</mrow>
<mrow>
\amp \sqbrac{f(x_0) + (x-x_0)f'(x_0) +  \dots + \trecip{(n-1)!} (x-x_0)^{n-1} f^{(n-1)}(x_0)}
</mrow>
</md>.
 Then <m>F</m> is <m>n</m> times differentiable on <m>(a,b)</m>.
 Moreover, for each <m>0 \leq m \lt n</m> we have
<me>
F^{(m)}(x_0) = 0
</me>,
 whilst for <m>m=n</m> we have
<me>
F^{(n)}(t) = f^{(n)}(t) \quad \text{for all } t \in (a,b).
</me>
 Letting <m>t\in [x_0,x]</m>, the mean value theorem (<xref ref="thm-mvt"/>) gives some <m>x_t</m> between <m>x_0</m> and <m>t</m> such that
<me>
|F^{(n-1)}(t)|  \leq (t-x_0) \abs{f^{(n)}(x_t)} .
</me>
 Write 
<me>
c := \sup\set{|f^{(n)}(t)| : t \text{ is between } x \text{ and } x_0}
</me>.
 Then we have shown that for all <m>t \in [x_0,x]</m> we have
<me>
 \abs{F^{(n-1)}(t)} \leq  c(t-x_0).
</me>
 As a consequence of <xref ref="lem-poly-comp"/>, we deduce that for <m>t \in [x_0,x]</m> we have
<me>
 \abs{F^{(n-2)}(t)} \leq  \trecip{2}c(t-x_0)^2.
</me>
 Re-applying <xref ref="lem-poly-comp"/>, for <m>t \in [x_0,x]</m> we have
<me>
 \abs{F^{(n-3)}(t)} \leq  \trecip{3!}c(t-x_0)^3.
</me>
 Iteratively applying <xref ref="lem-poly-comp"/>, for <m>t \in [x_0,x]</m> we obtain
<me>
\abs{F(t)} \leq  \trecip{n!}c(t-x_0)^n. 
</me>
</p>
</proof>
					</solution>
				</task>
			</exercise>
-->
			<exercise>
				<title>The exponential function</title>
				<task>
					<statement>Prove that the exponential function is infinitely differentiable and calculate its derivative.
					</statement>
					<solution>
					<proposition xml:id="prop-exp-properties">
					<statement>
 The exponential function <m>\exp : \R \to \R</m>, given by 
<me>
\exp(x) := \sum_{n=0}^\infty \frac{x^n}{n!}
</me>
is infinitely differentiable with first derivative
<men xml:id="eq-exp-deriv">
\exp'(x) = \exp(x).
</men>
</statement>
<proof>
 The infinite radius of convergence of the power series is proved in <xref ref="prop-exp-radius"/>.
 Infinite differentiability and the formula <xref ref="eq-exp-deriv"/> then both follow from <xref ref="cor-power-diff"/>.
 </proof>
</proposition>
	</solution>
				</task>
				<task>
					<statement>
					State and prove a formula for the reciprocal of the exponential function.
					</statement>
					<solution>
					<proposition xml:id="prop-exp-properties-2">
					<statement>
 For all  <m> x \in \R</m> we have the formula 
 <me>
 \exp(-x) = \recip{\exp(x)}.
 </me>
</statement>
<proof>
 The addition law <m> \exp(x+y) = \exp(x)\exp(y)</m> is established in <xref ref="prop-exp-add-law"/>. 
 From the addition law, it follows that
<me>
\exp(x)\exp(-x) = \exp(0) = 1.
</me>
Thus <m>\exp(-x) = 1/\exp(x)</m>.
 </proof>
</proposition>
					</solution>
				</task>
				<task>
					<statement>
					Justify why the exponential function is positive everywhere.</statement>
					<solution>
					By the inequality rule for sequences (<xref ref="prop-ineq-rule"/>), when <m>x \geq 0</m> we have
<me>
\exp(x) = \lim_{N\to \infty} \brac{1 + x + \trecip{2} x^2 + \dots + \trecip{N!} x^N} \geq 1.
</me>
 Hence <m>\exp(x) \geq 1</m> when <m>x \geq 0</m>.
 If <m>x \geq 0</m> then <m>\exp(-x) = \recip{\exp(x)} \gt0</m>.
 Thus for all <m>x \in \R</m> we have <m>\exp(x) \gt 0</m>.
					</solution>
				</task>
				<task>
					<statement>State and prove the limit of the exponential function as its argument tends to infinity.
					</statement>
					<solution>
					<m>\exp(x) \to \infty</m> as <m>x\to \infty</m>.
						<proof>
						By the definition of function limits (<xref ref="def-fn-lim"/>), we are required to show that if <m>a_n\to \infty</m> then <m>\exp(a_n)\to \infty</m>. We note that by definition of tending to infinity (<xref ref="def-seq-div-inf"/>) there exists <m>N\in \N</m> such that for all <m>n\geq N</m> we have <m>a_n\geq 0</m>. For <m>n\geq N</m> we therefore have the inequality
<me>
\exp(a_n) = 1+a_n+\trecip{2} a_n^2 + \dots \geq  a_n .
</me>
Since <m>a_n\to \infty</m> the one-sided sandwich rule for sequence limits (<xref ref="cor-sandwich"/>) gives that <m>\exp(a_n)\to \infty</m>.
						</proof>
					</solution>
				</task>
				<task>
					<statement>Justify why the exponential function is strictly increasing.
					</statement>
					<solution>
					Since <m>\exp'(x) = \exp(x) \gt0</m> and functions with positive derivative are strictly increasing (<xref ref="cor-mono-diff"/>), we deduce that <m>\exp</m> is strictly increasing on <m>\R</m>.
					</solution>
				</task>
				<task>
					<statement>
					State and prove how the exponential function is a bijection onto its image.
					</statement>
					<solution>
					<proposition xml:id="prop-exp-bij">
					<statement>
					<m>\exp</m> is a bijection from <m>\R</m> to <m>(0, \infty)</m>.
					</statement>
					<proof>
					Strictly increasing functions are injective, hence to show that <m>\exp</m> is bijective <m>\R \to (0, \infty)</m>, we must establish that every <m>y\gt 0</m> can be represented as <m>y = \exp(x)</m> for some <m>x \in \R</m>.
 Since <m>\exp(x) \to \infty</m> as <m>x \to \infty</m>, we have <m>\exp(-x) = 1/\exp(x) \to 0</m> as <m>x \to \infty</m>.
 Thus, for any <m>y \in (0, \infty)</m>, there exists <m>x_1 \lt  x_2</m> such that 
<me>
\exp(x_1) \leq y\leq \exp(x_2).
</me>
 Since differentiable functions are continuous, we may apply the intermediate value theorem to deduce the existence of <m>x \in [x_1, x_2]</m> such that <m>\exp(x) = y</m>.
 </proof>
 </proposition>
					</solution>
				</task>
			</exercise>
			<exercise>
				<title>The logarithm function</title>
				<task>
					<statement>Define the logarithm function and justify why this definition is valid.
					</statement>
					<solution>
					<definition>
					<title>Logarithm</title>
Since the exponential function <m>\exp : \R \to (0, \infty)</m> is bijective (<xref ref="prop-exp-bij"/>), it has a well-defined inverse <m>(0, \infty) \to \R</m> which we denote by <m> \log x</m> for <m>x \in (0, \infty)</m>.
</definition>					</solution>
				</task>
				<task>
					<statement>State and prove how the logarithm is a strictly increasing function, which is bijective onto its image.
					</statement>
					<solution>
					<proposition>
					<statement>
					<m>\log</m> is a strictly increasing bijection from <m>(0,\infty)</m> to <m>\R</m>.
					</statement>
					<proof>
					<p>
					The fact that <m>\log</m> is a bijection from <m>(0,\infty)</m> to <m>\R</m> follows from its definition as the inverse of the bijection <m>\exp : \R \to (0,\infty)</m>.
					</p>
					<p> To prove that it is strictly increasing, we argue by contradiction. 
 Let <m>x_1, x_2 \in (0, \infty)</m> with <m>x_1 \lt  x_2</m> and suppose that <m>\log(x_1) \geq \log(x_2)</m>. The increasing nature of the exponential function (<xref ref="prop-exp-properties"/>) gives that
<me>
x_1 = \exp\brac{\log x_1} \geq \exp\brac{\log x_2} = x_2.
</me>
 This is a contradiction, hence the logarithm is strictly increasing.
 </p>
					</proof>
					</proposition>
					</solution>
				</task>
				<task>
					<statement> State and prove how the logarithm function is continuous.
					</statement>
					<solution>
					<proposition xml:id="prop-log-cts">
					<statement>
					<m>\log</m> is continuous on <m>(0,\infty)</m>.
					</statement>
					<proof>
					Let <m>x_0\in (0, \infty)</m>. Using the epsilon-delta characterisation of continuity (<xref ref="cor-eps-delta-cts"/>), we are required to prove that for each <m>\eps \gt 0</m> there exists <m>\delta = \delta(x_0,\eps) \gt 0</m> such that 
					<me>
					|x-x_0| \leq \delta \quad \implies \quad |\log(x) - \log(x_0)| \leq \eps.
					</me>
					Writing <m>y:=\log(x)</m> and <m>y_0:=\log(x_0)</m> this is equivalent to showing that
					<men xml:id="eq-log-cts-to-prove">
					|\exp(y)-\exp(y_0)| \leq \delta \quad \implies \quad |y - y_0| \leq \eps.
					</men>
					By the mean value theorem (<xref ref="thm-mvt"/>), there exists <m>y_1</m> between <m>y</m> and <m>y_0</m> such that					
					<men xml:id="eq-log-cts-mvt">
					|\exp(y)-\exp(y_0)| = \exp(y_1)|y-y_0|.						</men>
					Since <m>\exp</m> is increasing, we have
					<me>
					\exp(y_1) \geq \exp\brac{\min\set{y_0,y}} = \min\set{x_0,x}
					</me>.
					Hence we derive <xref ref="eq-log-cts-to-prove"/> on taking
					<me>
					\delta(x_0,\eps) :=\min\set{\frac{x_0}{2}, \frac{\eps x_0}{2}},
					</me>
					since with this choice we have
					<me>
					\exp(y_1) \geq  \min\set{x_0,x_0-\tfrac{x_0}{2}}=\tfrac{x_0}{2}
					</me>,
					which yields the required implication on substitution into <xref ref="eq-log-cts-mvt"/>.
					</proof>
					</proposition>
					</solution>
				</task>
				<task>
					<statement>State and prove how the logarithm function is differentiable.
					</statement>
					<solution>
					<proposition>
					<statement>
					<m>\log</m> is differentiable on <m>(0,\infty)</m> with derivative
<me>
\log'(x) = \recip{x}.
</me>
					</statement>
					<proof>
					This follows from the inverse function theorem (<xref ref="thm-inverse-fn-1"/>) with <m>f := \exp</m>, since the hypotheses of that theorem are met, namely:
					<ul>
						<li>
						<m>\exp : \R \to (0,\infty)</m> is bijective  (this follows from <xref ref="prop-exp-bij"/>).
						</li>
						<li>
						<m>\exp^{-1}= \log</m> is continuous at every <m> x_0 \in (0,\infty)</m> (this follows from <xref ref="prop-log-cts"/>).
						</li>
						<li>
						<m>\exp</m> is differentiable at every <m>x_0\in \R</m> with non-zero derivative (this follows from <xref ref="prop-exp-properties"/>).
						</li>
					</ul>
					</proof>
					</proposition>
					</solution>
				</task>
				<task>
					<statement>State and prove the limit of the logarithm function as its argument tends to infinity.
					</statement>
					<solution>
					<proposition>
					<statement>
					<m>\log x \to \infty</m> as <m>x\to\infty</m>.
					</statement>
					<proof>	
					By the definition of function limits (<xref ref="def-fn-lim"/>), we are required to show that if <m>a_n\to \infty</m> then <m>\log(a_n)\to \infty</m>. Let <m> M \gt 0</m>. We note that by definition of tending to infinity (<xref ref="def-seq-div-inf"/>) there exists <m>N\in \N</m> such that for all <m>n\geq N</m> we have <m>a_n\geq \exp M</m>. Since <m>\log</m> is increasing this gives <m>\log a_n \geq M</m> for <m>n\geq N</m>. It follows that <m>\log(a_n)\to \infty</m> by the sequential definition of tending to infinity (<xref ref="def-seq-div-inf"/>).
					</proof>
					</proposition>
					</solution>
				</task>
				<!--
				<task>
					<statement>State and prove the Mercator series for the logarithm function.
					</statement>
					<solution>
					<proposition>
					<title>Mercator series for log</title>
<statement>
 Suppose that <m>|x| \lt  1</m>.
 Then we have the following power series expansion for the logarithm
<me>
\log(1+x) = \sum_{n=1}^\infty \frac{(-1)^{n-1}}{n} x^n.
</me>
</statement>
<proof>
 Iteratively differentiating the logarithm, we see that for <m>n \in \N</m> and <m>x \in (0,\infty)</m> we have
<me>
\log^{(n)}(x) = (-1)^{n-1} (n-1)! x^{-n}.
</me>
 Hence by Taylor's theorem (<xref ref="thm-taylor"/>), when <m>|x| \lt  1</m> there exists <m>x_n</m> between <m>x</m> and <m>0</m> such that <md>
 <mrow>
\abs{\log(1+x) - \sum_{n=1}^{N-1} \frac{(-1)^{n-1}}{n} x^n}\amp  \leq N! |x|^N  |1+x_n|^{-N}
</mrow>
<mrow>
\amp \leq \frac{N!|x|^N}{(1-|x|)^N}
= \frac{N!}{(|x|^{-1} -1)^N}.
</mrow>
</md>
THE PROOF BREAKS DOWN HERE. IT'S CLEAR THAT ONE NEEDS THE STRONGER FORM OF TAYLOR'S APPROXIMATION FOR THIS ARGUMENT TO WORK. GOING TO LEAVE OUT OF THIS YEAR'S NOTES
</proof></proposition>					</solution>
				</task>
				-->
			</exercise>
			<exercise>
				<title>Exponentiation to an arbitrary real</title>
				<task>
					<statement>Define exponentiation to an arbitrary real and the logarithm to an arbitrary base.
					</statement>
					<solution>
					<definition xml:id="def-exp-base">
<title>Exponentiation to an arbitrary real</title>
 Given <m>a \in (0, \infty)</m> and <m>x \in \R</m> we define
<me>
a^x := \exp(x\log a).
</me>
 One can check that this coincides with our normal definition of exponentiation  <m>a^n</m> when <m>n \in \Z</m>. Moreover, one can also check that
<m>
a^{1/n} = \sqrt[n]{a}
</m>, as we would expect.
</definition>
<definition>
<title>Logarithm to an arbitrary base</title>
 Given <m>a \in (0, \infty)</m> with <m>a \neq 1</m> and <m>x \in \R</m> we define
<me>
\log_a(x) := \frac{\log x}{\log a}.
</me>
</definition>					</solution>
				</task>
				<task>
					<statement>Justify why <m>a^x = b</m> if and only if <m>\log_a b = x</m>.
					</statement>
					<solution>
					Since <m>\log</m> is injective on <m>(0,\infty)</m>, we have 
<me>
a^x = b \iff \log(a^x) = \log(b).
</me>
 By definition we have <m>a^x := \exp(x\log a)</m>.
 Since <m>\log = \exp^{-1}</m> we deduce that
<me>
a^x = b \iff x\log a = \log b.
</me>
 Since <m>a \neq 1</m>, we have <m>\log a\neq0</m>, thus we may divide by <m>\log a</m> to conclude that
<me>
a^x = b \iff x = \frac{\log b}{\log a}.
</me>
 By definition <m>\log_a b = \log b / \log a</m>, establishing the claim.
					</solution>
				</task>
				<task>
					<statement>For <m>a >0</m> and <m>x,y \in \R</m>, prove the identities 
					<md alignment="gather">
					<mrow>
					\log(a^x) = x\log a,
					</mrow>
					<mrow>
					\brac{a^x}^y = a^{x y}.
					</mrow>
					</md>
					</statement>
					<solution>
					<p>
					By definition of exponentiation and the fact that <m>\log = \exp^{-1}</m>, we have
<me>
\log(a^x) = \log\brac{\exp(x\log a)} = x \log a.
</me>
This establishes the first identity.
</p>
<p>  
 Taking logarithms, the identity <m>\brac{a^x}^y = a^{x y}</m> is equivalent to 
<me>
\log\brac{\brac{a^x}^y} = \log\brac{a^{x y}}.
</me>
 This holds on applying our first identity to both sides (twice on the left-hand side).					
 </p>
 </solution>
				</task>
			</exercise>
			</subsection>
					</section>